# Phase 4.5 — Stabilization & Architecture Foundations

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Resolve architectural tensions and establish rendering foundations (SoA buffers, RenderGraph DAG, prefix sum, supervisor, backpressure) before exposing a public TypeScript API in Phase 5.

**Architecture:** Refactor the monolithic GPU buffer (20 f32/entity) into Structure-of-Arrays (4 independent buffers), extract renderer.ts into a modular RenderGraph DAG with RenderPass interface, add Worker heartbeat supervisor for graceful degradation A→B→C, and implement ring buffer backpressure with prioritized retry queue.

**Tech Stack:** Rust (hecs, glam, bytemuck), TypeScript (WebGPU, SharedArrayBuffer, Atomics), WGSL compute shaders

---

## Overview of Tasks

| # | Task | Subsystem | Estimated Steps |
|---|------|-----------|-----------------|
| 1 | MeshHandle + RenderPrimitive ECS components | Rust ECS | 5 |
| 2 | New command types (SetMeshHandle, SetRenderPrimitive, SetParent) | Rust ring buffer | 5 |
| 3 | Sync new command types to TypeScript | TS ring buffer | 5 |
| 4 | SoA buffer layout in Rust | Rust render_state | 5 |
| 5 | SoA WASM exports | Rust lib.rs | 5 |
| 6 | SAB header extension (16 → 32 bytes) | Rust + TS ring buffer | 5 |
| 7 | TypedArray fast path for ring buffer | TS ring buffer | 5 |
| 8 | Backpressure: PrioritizedCommandQueue | TS ring buffer | 5 |
| 9 | Worker Supervisor + heartbeat | TS supervisor | 5 |
| 10 | RenderPass interface + ResourcePool | TS render | 5 |
| 11 | CullPass extraction | TS render | 5 |
| 12 | ForwardPass extraction + RenderGraph DAG | TS render | 5 |
| 13 | Prefix sum (Blelloch) compute shader | WGSL + TS | 5 |
| 14 | TextureManager lazy allocation | TS textures | 5 |
| 15 | Dirty tracking (BitSet) in Rust | Rust render_state | 5 |

---

## Task 1: MeshHandle + RenderPrimitive ECS Components

**Files:**
- Modify: `crates/hyperion-core/src/components.rs`
- Test: inline `#[cfg(test)] mod tests` in same file

Phase 4.5 adds two new ECS components that create the indirection needed for multi-primitive rendering in Phase 5.5. Today every entity is implicitly a quad. These components make the geometry/primitive type explicit at zero cost (default values = current behavior).

### Step 1: Write failing tests for MeshHandle and RenderPrimitive

Add to the bottom of the existing `mod tests` block in `components.rs`:

```rust
#[test]
fn mesh_handle_default_is_unit_quad() {
    let mh = MeshHandle::default();
    assert_eq!(mh.0, 0, "MeshHandle 0 = unit quad");
}

#[test]
fn mesh_handle_is_pod() {
    let mh = MeshHandle(42);
    let bytes = bytemuck::bytes_of(&mh);
    assert_eq!(bytes.len(), 4);
    assert_eq!(u32::from_le_bytes(bytes.try_into().unwrap()), 42);
}

#[test]
fn render_primitive_default_is_quad() {
    let rp = RenderPrimitive::default();
    assert_eq!(rp.0, 0, "RenderPrimitive 0 = Quad");
}

#[test]
fn render_primitive_is_pod() {
    let rp = RenderPrimitive(2);
    let bytes = bytemuck::bytes_of(&rp);
    assert_eq!(bytes.len(), 1);
    assert_eq!(bytes[0], 2);
}
```

### Step 2: Run tests to verify they fail

Run: `cargo test -p hyperion-core components`
Expected: FAIL — `MeshHandle` and `RenderPrimitive` types do not exist yet.

### Step 3: Implement MeshHandle and RenderPrimitive

Add these structs to `components.rs`, after `BoundingRadius` and before the `Active` marker:

```rust
/// Mesh geometry handle. 0 = unit quad (default).
/// Range 0–31 core, 32–63 extended, 64–127 plugin.
#[derive(Debug, Clone, Copy, PartialEq, Pod, Zeroable)]
#[repr(C)]
pub struct MeshHandle(pub u32);

impl Default for MeshHandle {
    fn default() -> Self {
        Self(0)
    }
}

/// Render primitive type. Determines which GPU pipeline processes this entity.
/// Range 0–31 core, 32–63 extended, 64–127 plugin.
#[derive(Debug, Clone, Copy, PartialEq, Pod, Zeroable)]
#[repr(C)]
pub struct RenderPrimitive(pub u8);

impl Default for RenderPrimitive {
    fn default() -> Self {
        Self(0) // Quad
    }
}
```

### Step 4: Run tests to verify they pass

Run: `cargo test -p hyperion-core components`
Expected: ALL PASS (existing 8 tests + 4 new tests = 12 tests).

### Step 5: Commit

```bash
git add crates/hyperion-core/src/components.rs
git commit -m "feat(ecs): add MeshHandle and RenderPrimitive components

Phase 4.5 — two new #[repr(C)] Pod components that make geometry type
explicit. Default values preserve current quad behavior at zero cost.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 2: New Command Types in Rust

**Files:**
- Modify: `crates/hyperion-core/src/ring_buffer.rs`
- Modify: `crates/hyperion-core/src/command_processor.rs`
- Test: inline tests in both files

Add SetMeshHandle (8), SetRenderPrimitive (9), and SetParent (10) to the ring buffer protocol and command processor.

### Step 1: Write failing tests

Add to `ring_buffer.rs` test module:

```rust
#[test]
fn parse_set_mesh_handle() {
    // cmd=8, entity_id=1, payload=42u32 LE
    let data = [
        8, 1, 0, 0, 0, // cmd + entity_id
        42, 0, 0, 0,    // mesh handle u32 LE
    ];
    let cmds = parse_commands(&data);
    assert_eq!(cmds.len(), 1);
    assert_eq!(cmds[0].cmd_type, CommandType::SetMeshHandle);
    assert_eq!(cmds[0].entity_id, 1);
    let handle = u32::from_le_bytes(cmds[0].payload[0..4].try_into().unwrap());
    assert_eq!(handle, 42);
}

#[test]
fn parse_set_render_primitive() {
    // cmd=9, entity_id=2, payload=1u8 padded to 4 bytes
    let data = [
        9, 2, 0, 0, 0, // cmd + entity_id
        1, 0, 0, 0,     // render primitive u8 padded to u32
    ];
    let cmds = parse_commands(&data);
    assert_eq!(cmds.len(), 1);
    assert_eq!(cmds[0].cmd_type, CommandType::SetRenderPrimitive);
    assert_eq!(cmds[0].entity_id, 2);
    assert_eq!(cmds[0].payload[0], 1); // Line = 1
}

#[test]
fn parse_set_parent() {
    // cmd=10, entity_id=5, payload=parent_id=3 (u32 LE)
    let data = [
        10, 5, 0, 0, 0, // cmd + entity_id
        3, 0, 0, 0,      // parent entity id
    ];
    let cmds = parse_commands(&data);
    assert_eq!(cmds.len(), 1);
    assert_eq!(cmds[0].cmd_type, CommandType::SetParent);
    let parent = u32::from_le_bytes(cmds[0].payload[0..4].try_into().unwrap());
    assert_eq!(parent, 3);
}
```

Add to `command_processor.rs` test module:

```rust
#[test]
fn set_mesh_handle_updates_component() {
    let mut engine = Engine::new();
    let spawn = Command { cmd_type: CommandType::SpawnEntity, entity_id: 1, payload: [0; 16] };
    engine.process_commands(&[spawn]);

    let mut payload = [0u8; 16];
    payload[0..4].copy_from_slice(&42u32.to_le_bytes());
    let cmd = Command { cmd_type: CommandType::SetMeshHandle, entity_id: 1, payload };
    engine.process_commands(&[cmd]);

    let entity = engine.entity_map.get(1).unwrap();
    let mh = engine.world.get::<&MeshHandle>(entity).unwrap();
    assert_eq!(mh.0, 42);
}

#[test]
fn set_render_primitive_updates_component() {
    let mut engine = Engine::new();
    let spawn = Command { cmd_type: CommandType::SpawnEntity, entity_id: 1, payload: [0; 16] };
    engine.process_commands(&[spawn]);

    let mut payload = [0u8; 16];
    payload[0] = 2; // SDFGlyph
    let cmd = Command { cmd_type: CommandType::SetRenderPrimitive, entity_id: 1, payload };
    engine.process_commands(&[cmd]);

    let entity = engine.entity_map.get(1).unwrap();
    let rp = engine.world.get::<&RenderPrimitive>(entity).unwrap();
    assert_eq!(rp.0, 2);
}
```

### Step 2: Run tests to verify they fail

Run: `cargo test -p hyperion-core ring_buffer && cargo test -p hyperion-core command_proc`
Expected: FAIL — `SetMeshHandle`, `SetRenderPrimitive`, `SetParent` not in `CommandType` enum.

### Step 3: Implement new command types

In `ring_buffer.rs`, extend `CommandType`:

```rust
#[repr(u8)]
pub enum CommandType {
    Noop = 0,
    SpawnEntity = 1,
    DespawnEntity = 2,
    SetPosition = 3,
    SetRotation = 4,
    SetScale = 5,
    SetVelocity = 6,
    SetTextureLayer = 7,
    SetMeshHandle = 8,
    SetRenderPrimitive = 9,
    SetParent = 10,
}
```

Update `from_u8()` to handle 8, 9, 10.

Update `payload_size()`:
```rust
SetMeshHandle => 4,       // u32 LE
SetRenderPrimitive => 4,  // u8 padded to 4 for alignment
SetParent => 4,           // parent entity id (u32 LE), 0xFFFFFFFF = unparent
```

In `command_processor.rs`, add to `process_commands()` match:

```rust
CommandType::SetMeshHandle => {
    if let Some(entity) = entity_map.get(cmd.entity_id) {
        let handle = u32::from_le_bytes(cmd.payload[0..4].try_into().unwrap());
        if let Ok(mut mh) = world.get::<&mut MeshHandle>(entity) {
            mh.0 = handle;
        }
    }
}
CommandType::SetRenderPrimitive => {
    if let Some(entity) = entity_map.get(cmd.entity_id) {
        let prim = cmd.payload[0];
        if let Ok(mut rp) = world.get::<&mut RenderPrimitive>(entity) {
            rp.0 = prim;
        }
    }
}
CommandType::SetParent => {
    // Design only in Phase 4.5 — log or no-op
    // Full scene graph implementation in Phase 5
}
```

Also update `SpawnEntity` to include `MeshHandle::default()` and `RenderPrimitive::default()` in the spawn bundle.

### Step 4: Run tests to verify they pass

Run: `cargo test -p hyperion-core`
Expected: ALL PASS (48 existing + 5 new = 53 tests).

### Step 5: Commit

```bash
git add crates/hyperion-core/src/ring_buffer.rs crates/hyperion-core/src/command_processor.rs
git commit -m "feat(ring-buffer): add SetMeshHandle, SetRenderPrimitive, SetParent commands

Phase 4.5 — three new command types extending the ring buffer protocol.
SetParent is a no-op stub for Phase 5 scene graph.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 3: Sync New Command Types to TypeScript

**Files:**
- Modify: `ts/src/ring-buffer.ts`
- Test: `ts/src/ring-buffer.test.ts`

Keep the TS `CommandType` enum and `PAYLOAD_SIZES` in sync with Rust.

### Step 1: Write failing tests

Add to `ring-buffer.test.ts`:

```typescript
it('should write SetMeshHandle command', () => {
  const sab = new SharedArrayBuffer(1024);
  const rb = new RingBufferProducer(sab);
  const payload = new Float32Array(1);
  // Reinterpret u32 as f32 for the ring buffer encoding
  new Uint32Array(payload.buffer)[0] = 42;
  const ok = rb.writeCommand(CommandType.SetMeshHandle, 1, payload);
  expect(ok).toBe(true);
});

it('should write SetRenderPrimitive command', () => {
  const sab = new SharedArrayBuffer(1024);
  const rb = new RingBufferProducer(sab);
  const payload = new Float32Array(1);
  new Uint32Array(payload.buffer)[0] = 2; // SDFGlyph
  const ok = rb.writeCommand(CommandType.SetRenderPrimitive, 1, payload);
  expect(ok).toBe(true);
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/ring-buffer.test.ts`
Expected: FAIL — `CommandType.SetMeshHandle` and `SetRenderPrimitive` not defined.

### Step 3: Implement

In `ring-buffer.ts`, extend `CommandType`:

```typescript
export const enum CommandType {
  Noop = 0,
  SpawnEntity = 1,
  DespawnEntity = 2,
  SetPosition = 3,
  SetRotation = 4,
  SetScale = 5,
  SetVelocity = 6,
  SetTextureLayer = 7,
  SetMeshHandle = 8,
  SetRenderPrimitive = 9,
  SetParent = 10,
}
```

Update `PAYLOAD_SIZES`:

```typescript
const PAYLOAD_SIZES: Record<number, number> = {
  0: 0,  // Noop
  1: 0,  // SpawnEntity
  2: 0,  // DespawnEntity
  3: 12, // SetPosition
  4: 16, // SetRotation
  5: 12, // SetScale
  6: 12, // SetVelocity
  7: 4,  // SetTextureLayer
  8: 4,  // SetMeshHandle
  9: 4,  // SetRenderPrimitive
  10: 4, // SetParent
};
```

Add helper methods to `RingBufferProducer`:

```typescript
setMeshHandle(entityId: number, handle: number): boolean {
  const payload = new Float32Array(1);
  new Uint32Array(payload.buffer)[0] = handle;
  return this.writeCommand(CommandType.SetMeshHandle, entityId, payload);
}

setRenderPrimitive(entityId: number, primitive: number): boolean {
  const payload = new Float32Array(1);
  new Uint32Array(payload.buffer)[0] = primitive;
  return this.writeCommand(CommandType.SetRenderPrimitive, entityId, payload);
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/ring-buffer.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/ring-buffer.ts ts/src/ring-buffer.test.ts
git commit -m "feat(ts): sync SetMeshHandle, SetRenderPrimitive, SetParent commands

Phase 4.5 — TypeScript ring buffer protocol stays in sync with Rust.
Adds helper methods for new command types.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 4: SoA Buffer Layout in Rust

**Files:**
- Modify: `crates/hyperion-core/src/render_state.rs`
- Test: inline tests in same file

Refactor `collect_gpu()` from monolithic (20 f32/entity in one Vec) to Structure-of-Arrays (4 independent Vecs). This enables partial upload, better GPU cache performance, and extensibility.

### Step 1: Write failing tests for new SoA layout

Add to `render_state.rs` test module:

```rust
#[test]
fn collect_gpu_soa_produces_separate_buffers() {
    let mut world = World::new();
    world.spawn((
        Position(Vec3::new(1.0, 2.0, 3.0)),
        Rotation(Quat::IDENTITY),
        Scale(Vec3::ONE),
        ModelMatrix(Mat4::from_translation(Vec3::new(1.0, 2.0, 3.0)).to_cols_array()),
        BoundingRadius(0.5),
        TextureLayerIndex(0),
        MeshHandle::default(),
        RenderPrimitive::default(),
        Active,
    ));

    let mut rs = RenderState::new();
    rs.collect_gpu(&world);

    assert_eq!(rs.gpu_entity_count(), 1);
    // Transform buffer: 16 f32 per entity
    assert_eq!(rs.gpu_transforms().len(), 16);
    // Bounds buffer: 4 f32 per entity (xyz + radius)
    assert_eq!(rs.gpu_bounds().len(), 4);
    // RenderMeta buffer: 2 u32 per entity (mesh_handle + render_primitive)
    assert_eq!(rs.gpu_render_meta().len(), 2);
    // Texture indices: 1 u32 per entity
    assert_eq!(rs.gpu_tex_indices().len(), 1);
}

#[test]
fn soa_bounds_contain_position_and_radius() {
    let mut world = World::new();
    world.spawn((
        Position(Vec3::new(10.0, 20.0, 30.0)),
        Rotation(Quat::IDENTITY),
        Scale(Vec3::ONE),
        ModelMatrix(Mat4::IDENTITY.to_cols_array()),
        BoundingRadius(2.5),
        TextureLayerIndex(0),
        MeshHandle::default(),
        RenderPrimitive::default(),
        Active,
    ));

    let mut rs = RenderState::new();
    rs.collect_gpu(&world);
    let bounds = rs.gpu_bounds();
    assert_eq!(bounds[0], 10.0); // x
    assert_eq!(bounds[1], 20.0); // y
    assert_eq!(bounds[2], 30.0); // z
    assert_eq!(bounds[3], 2.5);  // radius
}

#[test]
fn soa_render_meta_packs_mesh_and_primitive() {
    let mut world = World::new();
    world.spawn((
        Position(Vec3::ZERO),
        Rotation(Quat::IDENTITY),
        Scale(Vec3::ONE),
        ModelMatrix(Mat4::IDENTITY.to_cols_array()),
        BoundingRadius(0.5),
        TextureLayerIndex(0),
        MeshHandle(7),
        RenderPrimitive(2),
        Active,
    ));

    let mut rs = RenderState::new();
    rs.collect_gpu(&world);
    let meta = rs.gpu_render_meta();
    assert_eq!(meta[0], 7);  // mesh handle
    assert_eq!(meta[1], 2);  // render primitive
}
```

### Step 2: Run tests to verify they fail

Run: `cargo test -p hyperion-core render_state`
Expected: FAIL — `gpu_transforms()`, `gpu_bounds()`, `gpu_render_meta()` methods don't exist.

### Step 3: Implement SoA layout

Replace `RenderState` internals:

```rust
pub struct RenderState {
    pub matrices: Vec<[f32; 16]>,       // Legacy path (unchanged)
    // SoA GPU buffers
    gpu_transforms: Vec<f32>,           // 16 f32/entity (mat4x4)
    gpu_bounds: Vec<f32>,               // 4 f32/entity (xyz + radius)
    gpu_render_meta: Vec<u32>,          // 2 u32/entity (mesh_handle + primitive)
    gpu_tex_indices: Vec<u32>,          // 1 u32/entity
    gpu_count: u32,
}
```

Rewrite `collect_gpu()`:

```rust
pub fn collect_gpu(&mut self, world: &World) {
    self.gpu_transforms.clear();
    self.gpu_bounds.clear();
    self.gpu_render_meta.clear();
    self.gpu_tex_indices.clear();
    self.gpu_count = 0;

    for (_entity, (pos, matrix, radius, tex, mesh, prim, _active)) in
        world.query::<(&Position, &ModelMatrix, &BoundingRadius, &TextureLayerIndex,
                        &MeshHandle, &RenderPrimitive, &Active)>().iter()
    {
        // Buffer A: Transform (16 f32)
        self.gpu_transforms.extend_from_slice(&matrix.0);

        // Buffer B: Bounds (4 f32)
        self.gpu_bounds.extend_from_slice(&[pos.0.x, pos.0.y, pos.0.z, radius.0]);

        // Buffer C: RenderMeta (2 u32)
        self.gpu_render_meta.push(mesh.0);
        self.gpu_render_meta.push(prim.0 as u32);

        // Texture indices (1 u32)
        self.gpu_tex_indices.push(tex.0);

        self.gpu_count += 1;
    }
}
```

Add new accessors:

```rust
pub fn gpu_transforms(&self) -> &[f32] { &self.gpu_transforms }
pub fn gpu_bounds(&self) -> &[f32] { &self.gpu_bounds }
pub fn gpu_render_meta(&self) -> &[u32] { &self.gpu_render_meta }
// gpu_tex_indices() already exists

pub fn gpu_transforms_ptr(&self) -> *const f32 {
    if self.gpu_transforms.is_empty() { std::ptr::null() }
    else { self.gpu_transforms.as_ptr() }
}
pub fn gpu_transforms_f32_len(&self) -> u32 { self.gpu_transforms.len() as u32 }

pub fn gpu_bounds_ptr(&self) -> *const f32 {
    if self.gpu_bounds.is_empty() { std::ptr::null() }
    else { self.gpu_bounds.as_ptr() }
}
pub fn gpu_bounds_f32_len(&self) -> u32 { self.gpu_bounds.len() as u32 }

pub fn gpu_render_meta_ptr(&self) -> *const u32 {
    if self.gpu_render_meta.is_empty() { std::ptr::null() }
    else { self.gpu_render_meta.as_ptr() }
}
pub fn gpu_render_meta_len(&self) -> u32 { self.gpu_render_meta.len() as u32 }
```

Remove the old `gpu_data` Vec and its accessors (`gpu_buffer`, `gpu_buffer_ptr`, `gpu_buffer_f32_len`).

### Step 4: Run tests to verify they pass

Run: `cargo test -p hyperion-core render_state`
Expected: ALL PASS.

**Note:** Some existing tests that relied on the old `gpu_data` layout (20 f32/entity) will need to be updated to use the new SoA accessors. Update them in the same step.

### Step 5: Commit

```bash
git add crates/hyperion-core/src/render_state.rs
git commit -m "refactor(render-state): SoA buffer layout for GPU entity data

Phase 4.5 — split monolithic 20 f32/entity buffer into 4 independent
SoA buffers: transforms (16 f32), bounds (4 f32), renderMeta (2 u32),
texIndices (1 u32). Enables partial upload and better GPU cache perf.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 5: SoA WASM Exports

**Files:**
- Modify: `crates/hyperion-core/src/lib.rs`
- Modify: `ts/src/engine-worker.ts`
- Modify: `ts/src/worker-bridge.ts`

Expose the new SoA buffers through WASM and update TypeScript to consume them.

### Step 1: Write failing test (TypeScript integration)

Add to `ts/src/integration.test.ts`:

```typescript
it('should produce SoA render state with separate buffers', async () => {
  // This test verifies the bridge contract
  // After a tick, latestRenderState should have separate SoA arrays
  const bridge = await createDirectBridge();
  bridge.commandBuffer.spawnEntity(0);
  bridge.commandBuffer.setPosition(0, 1, 2, 3);
  bridge.tick(1 / 60);

  const rs = bridge.latestRenderState;
  expect(rs).not.toBeNull();
  expect(rs!.entityCount).toBe(1);
  expect(rs!.transforms.length).toBe(16);  // 16 f32 per entity
  expect(rs!.bounds.length).toBe(4);       // 4 f32 per entity
  expect(rs!.renderMeta.length).toBe(2);   // 2 u32 per entity
  expect(rs!.texIndices.length).toBe(1);   // 1 u32 per entity
});
```

### Step 2: Run test to verify it fails

Run: `cd ts && npx vitest run src/integration.test.ts`
Expected: FAIL — `GPURenderState` doesn't have `transforms`, `bounds`, `renderMeta` fields.

### Step 3: Implement

**In `lib.rs`**, replace old GPU data exports with SoA exports:

```rust
// Remove: engine_gpu_data_ptr, engine_gpu_data_f32_len
// Add:
#[wasm_bindgen]
pub fn engine_gpu_transforms_ptr() -> *const f32 { /* ... */ }
#[wasm_bindgen]
pub fn engine_gpu_transforms_f32_len() -> u32 { /* ... */ }
#[wasm_bindgen]
pub fn engine_gpu_bounds_ptr() -> *const f32 { /* ... */ }
#[wasm_bindgen]
pub fn engine_gpu_bounds_f32_len() -> u32 { /* ... */ }
#[wasm_bindgen]
pub fn engine_gpu_render_meta_ptr() -> *const u32 { /* ... */ }
#[wasm_bindgen]
pub fn engine_gpu_render_meta_len() -> u32 { /* ... */ }
// engine_gpu_tex_indices_ptr and engine_gpu_tex_indices_len already exist
```

**In `worker-bridge.ts`**, update `GPURenderState`:

```typescript
export interface GPURenderState {
  entityCount: number;
  transforms: Float32Array;    // 16 f32/entity (mat4x4)
  bounds: Float32Array;        // 4 f32/entity (xyz + radius)
  renderMeta: Uint32Array;     // 2 u32/entity (meshHandle + renderPrimitive)
  texIndices: Uint32Array;     // 1 u32/entity
}
```

**In `engine-worker.ts`**, update the tick handler to read 4 separate buffers from WASM memory instead of 1 monolithic buffer. Copy each into its own transferable ArrayBuffer.

**In `worker-bridge.ts` createDirectBridge()**, update to read the 4 SoA buffers from WASM memory.

### Step 4: Run tests to verify they pass

Run: `cd ts && npm test`
Expected: ALL PASS.

**Note:** After changing lib.rs, rebuild WASM: `cd ts && npm run build:wasm`

### Step 5: Commit

```bash
git add crates/hyperion-core/src/lib.rs ts/src/engine-worker.ts ts/src/worker-bridge.ts ts/src/integration.test.ts
git commit -m "feat(wasm): expose SoA GPU buffers through WASM exports

Phase 4.5 — replaces monolithic engine_gpu_data_ptr with 4 separate
SoA exports: transforms, bounds, renderMeta, texIndices. Updates
engine-worker and worker-bridge to consume new format.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 6: SAB Header Extension (16 → 32 bytes)

**Files:**
- Modify: `crates/hyperion-core/src/ring_buffer.rs` (header offsets)
- Modify: `ts/src/ring-buffer.ts` (HEADER_SIZE, offsets)
- Test: both Rust and TS ring buffer tests

Extend the SharedArrayBuffer header from 16 to 32 bytes. New fields: heartbeat counters for Worker 1/2, supervisor flags, reserved padding. The data region shifts to offset 32.

### Step 1: Write failing tests

In `ring_buffer.rs` tests, add:

```rust
#[test]
fn header_size_is_32_bytes() {
    assert_eq!(HEADER_SIZE, 32);
}
```

In `ring-buffer.test.ts`, add:

```typescript
it('should use 32-byte header', () => {
  expect(HEADER_SIZE).toBe(32);
});
```

### Step 2: Run tests to verify they fail

Run: `cargo test -p hyperion-core ring_buffer` and `cd ts && npx vitest run src/ring-buffer.test.ts`
Expected: FAIL — `HEADER_SIZE` is currently 16.

### Step 3: Implement

**Rust (`ring_buffer.rs`):**
- Change header constant: `const HEADER_SIZE: usize = 32;`
- New layout:
  ```
  Offset 0-3:   write_head (u32 atomic)
  Offset 4-7:   read_head (u32 atomic)
  Offset 8-11:  capacity (u32)
  Offset 12-15: padding
  Offset 16-19: heartbeat_w1 (u32 atomic) — Worker 1 heartbeat
  Offset 20-23: heartbeat_w2 (u32 atomic) — Worker 2 heartbeat
  Offset 24-27: supervisor_flags (u32 atomic)
  Offset 28-31: overflow_counter (u32 atomic)
  Offset 32+:   data region
  ```
- Update `RingBufferConsumer::new()` — data pointer starts at `base + 32`
- Update `write_head()` / `read_head()` — offsets unchanged (still 0, 4)

**TypeScript (`ring-buffer.ts`):**
- `const HEADER_SIZE = 32;`
- `const HEARTBEAT_W1_OFFSET = 4;` (i32 index: byte 16 / 4 = 4)
- `const HEARTBEAT_W2_OFFSET = 5;` (i32 index: byte 20 / 4 = 5)
- `const SUPERVISOR_FLAGS_OFFSET = 6;` (i32 index: byte 24 / 4 = 6)
- `const OVERFLOW_COUNTER_OFFSET = 7;` (i32 index: byte 28 / 4 = 7)
- Update `RingBufferProducer` constructor — `this.data = new DataView(buffer, 32, this.capacity);`
- Update `extractUnread()` — data starts at byte 32

### Step 4: Run all ring buffer tests

Run: `cargo test -p hyperion-core ring_buffer && cd ts && npx vitest run src/ring-buffer.test.ts && cd ts && npx vitest run src/ring-buffer-utils.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add crates/hyperion-core/src/ring_buffer.rs ts/src/ring-buffer.ts ts/src/ring-buffer.test.ts ts/src/ring-buffer-utils.test.ts
git commit -m "refactor(sab): extend header from 16 to 32 bytes

Phase 4.5 — adds heartbeat counters (W1/W2), supervisor flags, and
overflow counter to the SAB header. Data region shifts to offset 32.
Prepares for Worker Supervisor and backpressure tracking.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 7: TypedArray Fast Path for Ring Buffer

**Files:**
- Modify: `ts/src/ring-buffer.ts`
- Test: `ts/src/ring-buffer.test.ts`

Replace DataView payload writes with direct TypedArray access on little-endian platforms (~4× speedup on payload-heavy operations).

### Step 1: Write failing test

Add to `ring-buffer.test.ts`:

```typescript
it('should use TypedArray fast path on little-endian', () => {
  // Verify IS_LITTLE_ENDIAN is detected
  expect(IS_LITTLE_ENDIAN).toBe(true); // Node.js is always LE
});
```

### Step 2: Run test to verify it fails

Run: `cd ts && npx vitest run src/ring-buffer.test.ts`
Expected: FAIL — `IS_LITTLE_ENDIAN` not exported.

### Step 3: Implement

Add at top of `ring-buffer.ts`:

```typescript
export const IS_LITTLE_ENDIAN =
  new Uint8Array(new Uint32Array([1]).buffer)[0] === 1;
```

In `RingBufferProducer`, add typed array views:

```typescript
private u8View: Uint8Array;
private u32View: Uint32Array;
private f32View: Float32Array;

constructor(buffer: SharedArrayBuffer | ArrayBuffer) {
  this.header = new Int32Array(buffer, 0, 8); // 32 bytes / 4 = 8 i32 slots
  this.capacity = buffer.byteLength - HEADER_SIZE;
  this.data = new DataView(buffer, HEADER_SIZE, this.capacity);
  // Fast path views (same underlying buffer, offset by header)
  this.u8View = new Uint8Array(buffer, HEADER_SIZE, this.capacity);
  this.u32View = new Uint32Array(buffer, HEADER_SIZE);
  this.f32View = new Float32Array(buffer, HEADER_SIZE);
}
```

In `writeCommand()`, use fast path for payload writes:

```typescript
// cmd byte (always DataView — single byte, no speed difference)
this.data.setUint8(writePos % this.capacity, cmd);
writePos++;

// entity_id (fast path for aligned writes)
const idPos = writePos % this.capacity;
if (IS_LITTLE_ENDIAN && (idPos & 3) === 0) {
  this.u32View[idPos >> 2] = entityId;
} else {
  this.data.setUint32(idPos, entityId, true);
}
writePos += 4;

// payload floats (fast path)
if (payload && IS_LITTLE_ENDIAN) {
  for (let i = 0; i < payload.length; i++) {
    const p = (writePos + i * 4) % this.capacity;
    if ((p & 3) === 0) {
      this.f32View[p >> 2] = payload[i];
    } else {
      this.data.setFloat32(p, payload[i], true);
    }
  }
} else if (payload) {
  for (let i = 0; i < payload.length; i++) {
    this.data.setFloat32((writePos + i * 4) % this.capacity, payload[i], true);
  }
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/ring-buffer.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/ring-buffer.ts ts/src/ring-buffer.test.ts
git commit -m "perf(ring-buffer): TypedArray fast path on little-endian

Phase 4.5 — uses Float32Array/Uint32Array directly for payload writes
when platform is little-endian (~99.97% of devices), falling back to
DataView for big-endian. ~4x speedup on payload-heavy writes.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 8: Backpressure — PrioritizedCommandQueue

**Files:**
- Create: `ts/src/backpressure.ts`
- Test: `ts/src/backpressure.test.ts`

When the ring buffer is full, buffer dropped commands in a TypeScript-side priority queue. Critical commands (Spawn, Despawn) are never lost; repeatable commands (SetPosition, etc.) keep only the latest value per entity.

### Step 1: Write failing tests

Create `ts/src/backpressure.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { PrioritizedCommandQueue, BackpressureMode } from './backpressure';
import { CommandType } from './ring-buffer';

describe('PrioritizedCommandQueue', () => {
  it('should enqueue critical commands and never drop them', () => {
    const q = new PrioritizedCommandQueue();
    q.enqueue(CommandType.SpawnEntity, 1);
    q.enqueue(CommandType.SpawnEntity, 2);
    q.enqueue(CommandType.DespawnEntity, 1);
    expect(q.criticalCount).toBe(3);
  });

  it('should keep only latest value per entity for overwrites', () => {
    const q = new PrioritizedCommandQueue();
    q.enqueue(CommandType.SetPosition, 1, new Float32Array([1, 2, 3]));
    q.enqueue(CommandType.SetPosition, 1, new Float32Array([4, 5, 6]));
    expect(q.overwriteCount).toBe(1); // only latest kept
  });

  it('should drain critical commands before overwrites', () => {
    const q = new PrioritizedCommandQueue();
    q.enqueue(CommandType.SetPosition, 1, new Float32Array([1, 2, 3]));
    q.enqueue(CommandType.SpawnEntity, 2);
    const drained: Array<{ cmd: number; entityId: number }> = [];
    q.drainTo({
      writeCommand(cmd: number, entityId: number) {
        drained.push({ cmd, entityId });
        return true;
      },
    } as any);
    expect(drained[0].cmd).toBe(CommandType.SpawnEntity); // critical first
    expect(drained[1].cmd).toBe(CommandType.SetPosition);
  });

  it('should stop draining when writeCommand returns false', () => {
    const q = new PrioritizedCommandQueue();
    q.enqueue(CommandType.SpawnEntity, 1);
    q.enqueue(CommandType.SpawnEntity, 2);
    let count = 0;
    q.drainTo({
      writeCommand() { count++; return count < 2; }, // reject second
    } as any);
    expect(q.criticalCount).toBe(1); // one remains
  });

  it('should clear after successful drain', () => {
    const q = new PrioritizedCommandQueue();
    q.enqueue(CommandType.SpawnEntity, 1);
    q.drainTo({
      writeCommand() { return true; },
    } as any);
    expect(q.criticalCount).toBe(0);
    expect(q.overwriteCount).toBe(0);
  });
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/backpressure.test.ts`
Expected: FAIL — module not found.

### Step 3: Implement

Create `ts/src/backpressure.ts`:

```typescript
import type { RingBufferProducer } from './ring-buffer';
import { CommandType } from './ring-buffer';

export type BackpressureMode = 'retry-queue' | 'drop';

interface QueuedCommand {
  cmd: CommandType;
  entityId: number;
  payload?: Float32Array;
}

export class PrioritizedCommandQueue {
  private critical: QueuedCommand[] = [];
  private overwrites = new Map<number, QueuedCommand>(); // key = entityId * 256 + cmd

  get criticalCount(): number { return this.critical.length; }
  get overwriteCount(): number { return this.overwrites.size; }

  enqueue(cmd: CommandType, entityId: number, payload?: Float32Array): void {
    if (cmd === CommandType.SpawnEntity || cmd === CommandType.DespawnEntity) {
      this.critical.push({ cmd, entityId, payload });
    } else {
      const key = entityId * 256 + cmd;
      this.overwrites.set(key, { cmd, entityId, payload });
    }
  }

  drainTo(rb: RingBufferProducer): void {
    // Critical first
    let i = 0;
    for (; i < this.critical.length; i++) {
      const c = this.critical[i];
      if (!rb.writeCommand(c.cmd, c.entityId, c.payload)) break;
    }
    this.critical.splice(0, i);

    // Overwrites
    const toDelete: number[] = [];
    for (const [key, c] of this.overwrites) {
      if (!rb.writeCommand(c.cmd, c.entityId, c.payload)) break;
      toDelete.push(key);
    }
    for (const key of toDelete) {
      this.overwrites.delete(key);
    }
  }

  clear(): void {
    this.critical.length = 0;
    this.overwrites.clear();
  }
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/backpressure.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/backpressure.ts ts/src/backpressure.test.ts
git commit -m "feat(backpressure): add PrioritizedCommandQueue

Phase 4.5 — when ring buffer is full, critical commands (Spawn/Despawn)
are queued and never lost. Repeatable commands keep only the latest
value per entity. Drained to ring buffer next frame with priority.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 9: Worker Supervisor + Heartbeat

**Files:**
- Create: `ts/src/supervisor.ts`
- Test: `ts/src/supervisor.test.ts`

Monitors Worker health via atomic heartbeat counter on SAB. Detects frozen/crashed workers and triggers degradation A→B→C.

### Step 1: Write failing tests

Create `ts/src/supervisor.test.ts`:

```typescript
import { describe, it, expect, vi } from 'vitest';
import { WorkerSupervisor, SupervisorConfig } from './supervisor';

function createMockSAB(): SharedArrayBuffer {
  return new SharedArrayBuffer(1024);
}

describe('WorkerSupervisor', () => {
  it('should detect heartbeat timeout after 3 missed checks', () => {
    const sab = createMockSAB();
    const onTimeout = vi.fn();
    const supervisor = new WorkerSupervisor(sab, { onTimeout, checkIntervalMs: 10 });

    // Heartbeat never incremented → should fire after 3 checks
    supervisor.check(); // miss 1
    supervisor.check(); // miss 2
    supervisor.check(); // miss 3 → timeout
    expect(onTimeout).toHaveBeenCalledTimes(1);
  });

  it('should reset miss count when heartbeat advances', () => {
    const sab = createMockSAB();
    const header = new Int32Array(sab);
    const onTimeout = vi.fn();
    const supervisor = new WorkerSupervisor(sab, { onTimeout, checkIntervalMs: 10 });

    supervisor.check(); // miss 1
    Atomics.add(header, 4, 1); // Worker increments heartbeat at i32 index 4 (byte 16)
    supervisor.check(); // heartbeat advanced → reset
    supervisor.check(); // miss 1 again
    supervisor.check(); // miss 2
    expect(onTimeout).not.toHaveBeenCalled(); // only 2 misses, need 3
  });

  it('should read overflow counter', () => {
    const sab = createMockSAB();
    const header = new Int32Array(sab);
    Atomics.store(header, 7, 42); // overflow counter at i32 index 7 (byte 28)
    const supervisor = new WorkerSupervisor(sab, {});
    expect(supervisor.overflowCount).toBe(42);
  });
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/supervisor.test.ts`
Expected: FAIL — module not found.

### Step 3: Implement

Create `ts/src/supervisor.ts`:

```typescript
export interface SupervisorConfig {
  onTimeout?: (workerId: number) => void;
  onModeChange?: (from: string, to: string, reason: string) => void;
  checkIntervalMs?: number;
  maxMissedBeats?: number;
}

const HEARTBEAT_W1_INDEX = 4; // i32 index (byte offset 16)
const HEARTBEAT_W2_INDEX = 5; // i32 index (byte offset 20)
const SUPERVISOR_FLAGS_INDEX = 6;
const OVERFLOW_COUNTER_INDEX = 7;

export class WorkerSupervisor {
  private header: Int32Array;
  private lastHeartbeat: number = 0;
  private missedBeats: number = 0;
  private maxMissed: number;
  private onTimeout?: (workerId: number) => void;

  constructor(sab: SharedArrayBuffer, config: SupervisorConfig) {
    this.header = new Int32Array(sab);
    this.maxMissed = config.maxMissedBeats ?? 3;
    this.onTimeout = config.onTimeout;
    this.lastHeartbeat = Atomics.load(this.header, HEARTBEAT_W1_INDEX);
  }

  check(): void {
    const current = Atomics.load(this.header, HEARTBEAT_W1_INDEX);
    if (current === this.lastHeartbeat) {
      this.missedBeats++;
      if (this.missedBeats >= this.maxMissed) {
        this.missedBeats = 0;
        this.onTimeout?.(1);
      }
    } else {
      this.missedBeats = 0;
      this.lastHeartbeat = current;
    }
  }

  get overflowCount(): number {
    return Atomics.load(this.header, OVERFLOW_COUNTER_INDEX);
  }

  incrementHeartbeat(workerIndex: number): void {
    const idx = workerIndex === 1 ? HEARTBEAT_W1_INDEX : HEARTBEAT_W2_INDEX;
    Atomics.add(this.header, idx, 1);
  }
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/supervisor.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/supervisor.ts ts/src/supervisor.test.ts
git commit -m "feat(supervisor): Worker heartbeat monitoring + timeout detection

Phase 4.5 — WorkerSupervisor reads atomic heartbeat counter from SAB,
detects 3 consecutive missed beats, and fires onTimeout callback for
degradation handling (A→B→C). Reads overflow counter for stats.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 10: RenderPass Interface + ResourcePool

**Files:**
- Create: `ts/src/render/render-pass.ts`
- Create: `ts/src/render/resource-pool.ts`
- Test: `ts/src/render/render-pass.test.ts`

Define the core abstractions for the modular rendering pipeline.

### Step 1: Write failing tests

Create `ts/src/render/render-pass.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import type { RenderPass, FrameState } from './render-pass';
import { ResourcePool } from './resource-pool';

describe('RenderPass interface', () => {
  it('should define required properties', () => {
    const pass: RenderPass = {
      name: 'test-pass',
      reads: ['input-texture'],
      writes: ['output-texture'],
      optional: false,
      setup: () => {},
      prepare: () => {},
      execute: () => {},
      resize: () => {},
      destroy: () => {},
    };
    expect(pass.name).toBe('test-pass');
    expect(pass.reads).toEqual(['input-texture']);
    expect(pass.writes).toEqual(['output-texture']);
    expect(pass.optional).toBe(false);
  });
});

describe('ResourcePool', () => {
  it('should register and retrieve named buffers', () => {
    const pool = new ResourcePool();
    const mockBuffer = {} as GPUBuffer;
    pool.setBuffer('transforms', mockBuffer);
    expect(pool.getBuffer('transforms')).toBe(mockBuffer);
  });

  it('should return undefined for unknown resources', () => {
    const pool = new ResourcePool();
    expect(pool.getBuffer('nonexistent')).toBeUndefined();
  });

  it('should register and retrieve named textures', () => {
    const pool = new ResourcePool();
    const mockTexture = {} as GPUTexture;
    pool.setTexture('depth', mockTexture);
    expect(pool.getTexture('depth')).toBe(mockTexture);
  });
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/render/render-pass.test.ts`
Expected: FAIL — modules not found.

### Step 3: Implement

Create `ts/src/render/render-pass.ts`:

```typescript
export interface FrameState {
  entityCount: number;
  transforms: Float32Array;    // 16 f32/entity
  bounds: Float32Array;        // 4 f32/entity
  renderMeta: Uint32Array;     // 2 u32/entity
  texIndices: Uint32Array;     // 1 u32/entity
  cameraViewProjection: Float32Array; // mat4x4
  canvasWidth: number;
  canvasHeight: number;
  deltaTime: number;
}

export interface RenderPass {
  readonly name: string;
  readonly reads: string[];
  readonly writes: string[];
  readonly optional: boolean;
  setup(device: GPUDevice, resources: import('./resource-pool').ResourcePool): void;
  prepare(device: GPUDevice, frame: FrameState): void;
  execute(encoder: GPUCommandEncoder, frame: FrameState,
          resources: import('./resource-pool').ResourcePool): void;
  resize(width: number, height: number): void;
  destroy(): void;
}
```

Create `ts/src/render/resource-pool.ts`:

```typescript
export class ResourcePool {
  private buffers = new Map<string, GPUBuffer>();
  private textures = new Map<string, GPUTexture>();
  private textureViews = new Map<string, GPUTextureView>();

  setBuffer(name: string, buffer: GPUBuffer): void {
    this.buffers.set(name, buffer);
  }

  getBuffer(name: string): GPUBuffer | undefined {
    return this.buffers.get(name);
  }

  setTexture(name: string, texture: GPUTexture): void {
    this.textures.set(name, texture);
  }

  getTexture(name: string): GPUTexture | undefined {
    return this.textures.get(name);
  }

  setTextureView(name: string, view: GPUTextureView): void {
    this.textureViews.set(name, view);
  }

  getTextureView(name: string): GPUTextureView | undefined {
    return this.textureViews.get(name);
  }

  destroy(): void {
    for (const buf of this.buffers.values()) buf.destroy();
    for (const tex of this.textures.values()) tex.destroy();
    this.buffers.clear();
    this.textures.clear();
    this.textureViews.clear();
  }
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/render/render-pass.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/render/render-pass.ts ts/src/render/resource-pool.ts ts/src/render/render-pass.test.ts
git commit -m "feat(render): add RenderPass interface and ResourcePool

Phase 4.5 — defines FrameState (SoA fields), RenderPass interface
(reads/writes/optional), and ResourcePool for named GPU resource
management. Foundation for modular RenderGraph DAG.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 11: CullPass Extraction

**Files:**
- Create: `ts/src/render/passes/cull-pass.ts`
- Modify: `ts/src/shaders/cull.wgsl` (update bindings for SoA)
- Test: `ts/src/render/passes/cull-pass.test.ts`

Extract the compute culling logic from the monolithic `renderer.ts` into a standalone `CullPass` implementing the `RenderPass` interface. Update the cull shader to read from SoA buffers (transforms + bounds separately).

### Step 1: Write failing test

Create `ts/src/render/passes/cull-pass.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { CullPass } from './cull-pass';

describe('CullPass', () => {
  it('should implement RenderPass interface', () => {
    const pass = new CullPass();
    expect(pass.name).toBe('cull');
    expect(pass.reads).toContain('entity-transforms');
    expect(pass.reads).toContain('entity-bounds');
    expect(pass.writes).toContain('visible-indices');
    expect(pass.writes).toContain('indirect-args');
    expect(pass.optional).toBe(false);
  });
});
```

### Step 2: Run test to verify it fails

Run: `cd ts && npx vitest run src/render/passes/cull-pass.test.ts`
Expected: FAIL — module not found.

### Step 3: Implement

Create `ts/src/render/passes/cull-pass.ts`:

```typescript
import type { RenderPass, FrameState } from '../render-pass';
import type { ResourcePool } from '../resource-pool';
import cullShaderSource from '../../shaders/cull.wgsl?raw';

const MAX_ENTITIES = 100_000;
const WORKGROUP_SIZE = 256;

export class CullPass implements RenderPass {
  readonly name = 'cull';
  readonly reads = ['entity-transforms', 'entity-bounds'];
  readonly writes = ['visible-indices', 'indirect-args'];
  readonly optional = false;

  private pipeline: GPUComputePipeline | null = null;
  private bindGroup: GPUBindGroup | null = null;
  private cullUniformBuffer: GPUBuffer | null = null;

  setup(device: GPUDevice, resources: ResourcePool): void {
    const shaderModule = device.createShaderModule({ code: cullShaderSource });

    this.cullUniformBuffer = device.createBuffer({
      size: 112, // 6 planes (96B) + entityCount (4B) + padding (12B)
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });

    const transformBuffer = resources.getBuffer('entity-transforms')!;
    const boundsBuffer = resources.getBuffer('entity-bounds')!;
    const visibleIndicesBuffer = resources.getBuffer('visible-indices')!;
    const indirectBuffer = resources.getBuffer('indirect-args')!;

    const bindGroupLayout = device.createBindGroupLayout({
      entries: [
        { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
        { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
        { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },
        { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
        { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
      ],
    });

    this.pipeline = device.createComputePipeline({
      layout: device.createPipelineLayout({ bindGroupLayouts: [bindGroupLayout] }),
      compute: { module: shaderModule, entryPoint: 'cull_main' },
    });

    this.bindGroup = device.createBindGroup({
      layout: bindGroupLayout,
      entries: [
        { binding: 0, resource: { buffer: this.cullUniformBuffer } },
        { binding: 1, resource: { buffer: transformBuffer } },
        { binding: 2, resource: { buffer: boundsBuffer } },
        { binding: 3, resource: { buffer: visibleIndicesBuffer } },
        { binding: 4, resource: { buffer: indirectBuffer } },
      ],
    });
  }

  prepare(device: GPUDevice, frame: FrameState): void {
    // Upload frustum planes + entity count
    // (Implementation details: extract planes from frame.cameraViewProjection)
  }

  execute(encoder: GPUCommandEncoder, frame: FrameState, resources: ResourcePool): void {
    const pass = encoder.beginComputePass();
    pass.setPipeline(this.pipeline!);
    pass.setBindGroup(0, this.bindGroup!);
    pass.dispatchWorkgroups(Math.ceil(frame.entityCount / WORKGROUP_SIZE));
    pass.end();
  }

  resize(_width: number, _height: number): void { /* no-op for compute */ }

  destroy(): void {
    this.cullUniformBuffer?.destroy();
  }
}
```

Update `cull.wgsl` to read from separate SoA buffers:

```wgsl
@group(0) @binding(0) var<uniform> cullUniforms: CullUniforms;
@group(0) @binding(1) var<storage, read> transforms: array<mat4x4f>;
@group(0) @binding(2) var<storage, read> bounds: array<vec4f>;
@group(0) @binding(3) var<storage, read_write> visibleIndices: array<u32>;
@group(0) @binding(4) var<storage, read_write> drawArgs: DrawIndirectArgs;
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/render/passes/cull-pass.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/render/passes/cull-pass.ts ts/src/render/passes/cull-pass.test.ts ts/src/shaders/cull.wgsl
git commit -m "refactor(render): extract CullPass from monolithic renderer

Phase 4.5 — CullPass implements RenderPass interface, reads SoA
transforms + bounds buffers separately. Cull shader updated for
SoA bindings. First step of renderer modularization.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 12: ForwardPass + RenderGraph DAG

**Files:**
- Create: `ts/src/render/passes/forward-pass.ts`
- Create: `ts/src/render/render-graph.ts`
- Modify: `ts/src/shaders/basic.wgsl` (SoA bindings)
- Test: `ts/src/render/render-graph.test.ts`

Extract the render pass from `renderer.ts`, then build the RenderGraph DAG that orchestrates pass execution via topological sort.

### Step 1: Write failing tests

Create `ts/src/render/render-graph.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { RenderGraph } from './render-graph';
import type { RenderPass, FrameState } from './render-pass';

function mockPass(name: string, reads: string[], writes: string[], optional = false): RenderPass {
  return {
    name, reads, writes, optional,
    setup: () => {}, prepare: () => {}, execute: () => {},
    resize: () => {}, destroy: () => {},
  };
}

describe('RenderGraph', () => {
  it('should compile 2 passes in correct order', () => {
    const graph = new RenderGraph();
    graph.addPass(mockPass('forward', ['visible-indices'], ['swapchain']));
    graph.addPass(mockPass('cull', ['entity-transforms'], ['visible-indices']));
    const order = graph.compile();
    expect(order[0]).toBe('cull');    // cull before forward
    expect(order[1]).toBe('forward');
  });

  it('should cull dead optional passes', () => {
    const graph = new RenderGraph();
    graph.addPass(mockPass('cull', [], ['visible-indices']));
    graph.addPass(mockPass('forward', ['visible-indices'], ['swapchain']));
    graph.addPass(mockPass('unused-optional', [], ['orphan-output'], true));
    const order = graph.compile();
    expect(order).not.toContain('unused-optional');
    expect(order.length).toBe(2);
  });

  it('should detect cycles and throw', () => {
    const graph = new RenderGraph();
    graph.addPass(mockPass('a', ['c-out'], ['a-out']));
    graph.addPass(mockPass('b', ['a-out'], ['b-out']));
    graph.addPass(mockPass('c', ['b-out'], ['c-out']));
    expect(() => graph.compile()).toThrow(/cycle/i);
  });

  it('should support addPass and removePass with lazy recompile', () => {
    const graph = new RenderGraph();
    graph.addPass(mockPass('cull', [], ['visible-indices']));
    graph.addPass(mockPass('forward', ['visible-indices'], ['swapchain']));
    graph.compile();

    graph.removePass('forward');
    expect(graph.needsRecompile).toBe(true);
  });

  it('should throw on duplicate pass name', () => {
    const graph = new RenderGraph();
    graph.addPass(mockPass('cull', [], ['out']));
    expect(() => graph.addPass(mockPass('cull', [], ['out2']))).toThrow(/already registered/);
  });
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/render/render-graph.test.ts`
Expected: FAIL — module not found.

### Step 3: Implement

Create `ts/src/render/render-graph.ts`:

```typescript
import type { RenderPass, FrameState } from './render-pass';
import type { ResourcePool } from './resource-pool';

export class RenderGraph {
  private passes = new Map<string, RenderPass>();
  private executionOrder: string[] = [];
  private _needsRecompile = true;

  get needsRecompile(): boolean { return this._needsRecompile; }

  addPass(pass: RenderPass): void {
    if (this.passes.has(pass.name)) {
      throw new Error(`RenderPass '${pass.name}' already registered`);
    }
    this.passes.set(pass.name, pass);
    this._needsRecompile = true;
  }

  removePass(name: string): void {
    const pass = this.passes.get(name);
    if (pass) {
      pass.destroy();
      this.passes.delete(name);
      this._needsRecompile = true;
    }
  }

  compile(): string[] {
    // Topological sort (Kahn's algorithm)
    const resourceWriters = new Map<string, string>(); // resource → pass name
    const adj = new Map<string, string[]>(); // pass → depends-on passes
    const inDegree = new Map<string, number>();

    for (const [name, pass] of this.passes) {
      adj.set(name, []);
      inDegree.set(name, 0);
      for (const w of pass.writes) resourceWriters.set(w, name);
    }

    // Build edges: if pass B reads resource X, and pass A writes X, then A → B
    for (const [name, pass] of this.passes) {
      for (const r of pass.reads) {
        const writer = resourceWriters.get(r);
        if (writer && writer !== name) {
          adj.get(writer)!.push(name);
          inDegree.set(name, (inDegree.get(name) ?? 0) + 1);
        }
      }
    }

    // Kahn's
    const queue: string[] = [];
    for (const [name, deg] of inDegree) {
      if (deg === 0) queue.push(name);
    }

    const sorted: string[] = [];
    while (queue.length > 0) {
      const current = queue.shift()!;
      sorted.push(current);
      for (const neighbor of adj.get(current) ?? []) {
        const newDeg = (inDegree.get(neighbor) ?? 0) - 1;
        inDegree.set(neighbor, newDeg);
        if (newDeg === 0) queue.push(neighbor);
      }
    }

    if (sorted.length !== this.passes.size) {
      throw new Error('RenderGraph has a cycle — cannot compile');
    }

    // Dead-pass culling: backward pass from swapchain
    const alive = new Set<string>();
    const resourceReaders = new Map<string, string[]>();
    for (const [name, pass] of this.passes) {
      for (const r of pass.reads) {
        if (!resourceReaders.has(r)) resourceReaders.set(r, []);
        resourceReaders.get(r)!.push(name);
      }
    }

    // Mark passes writing to 'swapchain' as alive, then propagate backwards
    for (const [name, pass] of this.passes) {
      if (pass.writes.includes('swapchain') || !pass.optional) {
        alive.add(name);
      }
    }
    // Propagate: if a pass is alive, all passes it reads from are alive
    let changed = true;
    while (changed) {
      changed = false;
      for (const name of alive) {
        const pass = this.passes.get(name)!;
        for (const r of pass.reads) {
          const writer = resourceWriters.get(r);
          if (writer && !alive.has(writer)) {
            alive.add(writer);
            changed = true;
          }
        }
      }
    }

    this.executionOrder = sorted.filter(name => alive.has(name));
    this._needsRecompile = false;
    return [...this.executionOrder];
  }

  render(device: GPUDevice, frame: FrameState, resources: ResourcePool): void {
    if (this._needsRecompile) this.compile();

    for (const name of this.executionOrder) {
      this.passes.get(name)!.prepare(device, frame);
    }

    const encoder = device.createCommandEncoder();
    for (const name of this.executionOrder) {
      this.passes.get(name)!.execute(encoder, frame, resources);
    }
    device.queue.submit([encoder.finish()]);
  }

  destroy(): void {
    for (const pass of this.passes.values()) pass.destroy();
    this.passes.clear();
  }
}
```

Create `ts/src/render/passes/forward-pass.ts` — extract render pass logic from the existing `renderer.ts` into a `ForwardPass` implementing `RenderPass`. This file reads `visible-indices` and writes to `swapchain`.

Update `basic.wgsl` for SoA bindings (group 1 now has separate storage buffers for transforms and texIndices).

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/render/render-graph.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/render/render-graph.ts ts/src/render/render-graph.test.ts ts/src/render/passes/forward-pass.ts ts/src/shaders/basic.wgsl
git commit -m "feat(render): RenderGraph DAG with topological sort + dead-pass culling

Phase 4.5 — modular rendering pipeline. RenderGraph compiles pass
execution order via Kahn's algorithm, culls dead optional passes,
supports addPass/removePass with lazy recompile. ForwardPass extracted
from monolithic renderer.ts.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 13: Prefix Sum (Blelloch) Compute Shader

**Files:**
- Create: `ts/src/shaders/prefix-sum.wgsl`
- Modify: `ts/src/render/passes/cull-pass.ts` (integrate prefix sum + stream compaction)
- Test: `ts/src/render/passes/prefix-sum.test.ts`

Replace the current `atomicAdd` approach with proper prefix sum + stream compaction. The current approach (atomic increment per visible entity) has non-deterministic ordering and doesn't support grouping by `RenderPrimitiveType`.

### Step 1: Write failing test

Create `ts/src/render/passes/prefix-sum.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { exclusiveScanCPU } from './prefix-sum-reference';

describe('Prefix sum reference implementation', () => {
  it('should compute exclusive scan for simple input', () => {
    const visibility = [0, 1, 1, 0, 1, 0, 1, 1];
    const result = exclusiveScanCPU(visibility);
    expect(result).toEqual([0, 0, 1, 2, 2, 3, 3, 4]);
  });

  it('should handle all-visible', () => {
    const visibility = [1, 1, 1, 1];
    const result = exclusiveScanCPU(visibility);
    expect(result).toEqual([0, 1, 2, 3]);
  });

  it('should handle all-invisible', () => {
    const visibility = [0, 0, 0, 0];
    const result = exclusiveScanCPU(visibility);
    expect(result).toEqual([0, 0, 0, 0]);
  });

  it('should handle single element', () => {
    expect(exclusiveScanCPU([1])).toEqual([0]);
    expect(exclusiveScanCPU([0])).toEqual([0]);
  });

  it('should produce correct compacted indices', () => {
    const visibility = [0, 1, 1, 0, 1, 0, 1, 1];
    const scan = exclusiveScanCPU(visibility);
    const compacted: number[] = [];
    for (let i = 0; i < visibility.length; i++) {
      if (visibility[i] === 1) {
        compacted[scan[i]] = i;
      }
    }
    expect(compacted).toEqual([1, 2, 4, 6, 7]);
  });
});
```

### Step 2: Run test to verify it fails

Run: `cd ts && npx vitest run src/render/passes/prefix-sum.test.ts`
Expected: FAIL — module not found.

### Step 3: Implement

Create `ts/src/render/passes/prefix-sum-reference.ts` (CPU reference for testing):

```typescript
/** Exclusive prefix sum (Blelloch scan, CPU reference implementation) */
export function exclusiveScanCPU(input: number[]): number[] {
  const n = input.length;
  const output = new Array(n).fill(0);
  if (n === 0) return output;

  // Copy input
  for (let i = 0; i < n; i++) output[i] = input[i];

  // Up-sweep (reduce)
  for (let d = 1; d < n; d *= 2) {
    for (let i = n - 1; i >= d; i -= d * 2) {
      output[i] += output[i - d];
    }
  }

  // Set last to 0 (exclusive scan)
  output[n - 1] = 0;

  // Down-sweep
  for (let d = Math.floor(n / 2); d >= 1; d = Math.floor(d / 2)) {
    for (let i = n - 1; i >= d; i -= d * 2) {
      const t = output[i - d];
      output[i - d] = output[i];
      output[i] += t;
    }
  }

  return output;
}
```

Create `ts/src/shaders/prefix-sum.wgsl`:

```wgsl
// Blelloch exclusive prefix sum (workgroup-level, 256 elements)
// For >256 entities, dispatch multiple workgroups + second-level scan

@group(0) @binding(0) var<storage, read_write> data: array<u32>;
@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;

var<workgroup> temp: array<u32, 512>;

@compute @workgroup_size(256)
fn prefix_sum_main(
    @builtin(global_invocation_id) gid: vec3u,
    @builtin(local_invocation_id) lid: vec3u,
    @builtin(workgroup_id) wid: vec3u,
) {
    let n = 256u * 2u; // Each workgroup processes 512 elements
    let offset = wid.x * n;
    let thid = lid.x;

    // Load into shared memory
    temp[2u * thid] = data[offset + 2u * thid];
    temp[2u * thid + 1u] = data[offset + 2u * thid + 1u];

    // Up-sweep
    var d = 1u;
    var stride = n;
    loop {
        stride = stride >> 1u;
        if (stride == 0u) { break; }
        workgroupBarrier();
        if (thid < stride) {
            let ai = d * (2u * thid + 1u) - 1u;
            let bi = d * (2u * thid + 2u) - 1u;
            temp[bi] += temp[ai];
        }
        d = d << 1u;
    }

    // Store block sum, set last to 0
    if (thid == 0u) {
        blockSums[wid.x] = temp[n - 1u];
        temp[n - 1u] = 0u;
    }

    // Down-sweep
    d = n >> 1u;
    loop {
        if (d == 0u) { break; }
        workgroupBarrier();
        let stride2 = n / (d << 1u);
        if (thid < stride2) {
            let ai = d * (2u * thid + 1u) - 1u;
            let bi = d * (2u * thid + 2u) - 1u;
            let t = temp[ai];
            temp[ai] = temp[bi];
            temp[bi] += t;
        }
        d = d >> 1u;
    }
    workgroupBarrier();

    // Write back
    data[offset + 2u * thid] = temp[2u * thid];
    data[offset + 2u * thid + 1u] = temp[2u * thid + 1u];
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/render/passes/prefix-sum.test.ts`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add ts/src/render/passes/prefix-sum-reference.ts ts/src/render/passes/prefix-sum.test.ts ts/src/shaders/prefix-sum.wgsl
git commit -m "feat(render): Blelloch prefix sum compute shader + CPU reference

Phase 4.5 — WGSL workgroup-level prefix sum (Blelloch algorithm) for
stream compaction. CPU reference implementation for testing. Foundation
for GPU-driven rendering with grouped indirect draws.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 14: TextureManager Lazy Allocation

**Files:**
- Modify: `ts/src/texture-manager.ts`
- Test: `ts/src/texture-manager.test.ts`

Replace upfront 256-layer allocation per tier (~340 MB total) with lazy allocation starting at 16 layers, growing exponentially (16→32→64→128→256). Initial memory drops from 340 MB to ~1.3 MB.

### Step 1: Write failing tests

Add to `texture-manager.test.ts`:

```typescript
it('should not allocate tiers upfront (lazy)', () => {
  // After construction, no GPU textures should be created
  // (requires mock or tracking allocated layers)
  const tm = new TextureManager(mockDevice);
  expect(tm.getAllocatedLayers(0)).toBe(0);
  expect(tm.getAllocatedLayers(1)).toBe(0);
  expect(tm.getAllocatedLayers(2)).toBe(0);
  expect(tm.getAllocatedLayers(3)).toBe(0);
});

it('should allocate 16 layers on first load to a tier', () => {
  const tm = new TextureManager(mockDevice);
  // Loading first texture to tier 0 should allocate 16 layers
  tm.ensureTierCapacity(0, 1);
  expect(tm.getAllocatedLayers(0)).toBe(16);
});

it('should grow exponentially: 16 → 32 → 64 → 128 → 256', () => {
  const tm = new TextureManager(mockDevice);
  tm.ensureTierCapacity(0, 1);   // → 16
  expect(tm.getAllocatedLayers(0)).toBe(16);
  tm.ensureTierCapacity(0, 17);  // → 32
  expect(tm.getAllocatedLayers(0)).toBe(32);
  tm.ensureTierCapacity(0, 33);  // → 64
  expect(tm.getAllocatedLayers(0)).toBe(64);
  tm.ensureTierCapacity(0, 65);  // → 128
  expect(tm.getAllocatedLayers(0)).toBe(128);
  tm.ensureTierCapacity(0, 129); // → 256
  expect(tm.getAllocatedLayers(0)).toBe(256);
});
```

### Step 2: Run tests to verify they fail

Run: `cd ts && npx vitest run src/texture-manager.test.ts`
Expected: FAIL — `getAllocatedLayers` and `ensureTierCapacity` don't exist, and constructor currently allocates all 256 layers upfront.

### Step 3: Implement

Refactor `TextureManager`:

```typescript
interface TierState {
  size: number;          // pixel dimension (64, 128, 256, 512)
  texture: GPUTexture | null;
  allocatedLayers: number;
  nextFreeLayer: number;
  bindGroupDirty: boolean;
}

class TextureManager {
  private tiers: TierState[];

  constructor(device: GPUDevice) {
    this.tiers = TIER_SIZES.map(size => ({
      size,
      texture: null,        // Not allocated until needed
      allocatedLayers: 0,
      nextFreeLayer: 0,
      bindGroupDirty: false,
    }));
  }

  getAllocatedLayers(tierIdx: number): number {
    return this.tiers[tierIdx].allocatedLayers;
  }

  ensureTierCapacity(tierIdx: number, neededLayers: number): void {
    const tier = this.tiers[tierIdx];
    if (tier.allocatedLayers >= neededLayers) return;

    // Exponential growth: 0 → 16 → 32 → 64 → 128 → 256
    let newCapacity = tier.allocatedLayers === 0 ? 16 : tier.allocatedLayers;
    while (newCapacity < neededLayers) {
      newCapacity = Math.min(MAX_LAYERS_PER_TIER, newCapacity * 2);
    }

    const newTexture = this.device.createTexture({
      size: [tier.size, tier.size, newCapacity],
      format: 'rgba8unorm',
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
             | GPUTextureUsage.RENDER_ATTACHMENT,
    });

    // Copy existing layers if resizing
    if (tier.texture && tier.allocatedLayers > 0) {
      const encoder = this.device.createCommandEncoder();
      for (let layer = 0; layer < tier.allocatedLayers; layer++) {
        encoder.copyTextureToTexture(
          { texture: tier.texture, origin: [0, 0, layer] },
          { texture: newTexture, origin: [0, 0, layer] },
          [tier.size, tier.size, 1],
        );
      }
      this.device.queue.submit([encoder.finish()]);
      tier.texture.destroy();
    }

    tier.texture = newTexture;
    tier.allocatedLayers = newCapacity;
    tier.bindGroupDirty = true;
  }
}
```

### Step 4: Run tests to verify they pass

Run: `cd ts && npx vitest run src/texture-manager.test.ts`
Expected: ALL PASS.

**Note:** Existing tests that depend on the old constructor will need updating (no more upfront 256-layer allocation).

### Step 5: Commit

```bash
git add ts/src/texture-manager.ts ts/src/texture-manager.test.ts
git commit -m "perf(textures): lazy tier allocation with exponential growth

Phase 4.5 — replace upfront 256-layer allocation (~340 MB) with lazy
growth: 0 → 16 → 32 → 64 → 128 → 256 layers per tier. Initial memory
drops to ~1.3 MB (99.6% reduction). GPU copy on tier resize.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Task 15: Dirty Tracking (BitSet) in Rust

**Files:**
- Modify: `crates/hyperion-core/src/render_state.rs`
- Test: inline tests

Add per-buffer dirty tracking via BitSet. When < 30% of entities are dirty, the GPU upload can skip unchanged entities. This prepares for partial upload in Phase 5 (the TS side reads the dirty flags to decide full vs partial upload).

### Step 1: Write failing tests

Add to `render_state.rs` tests:

```rust
#[test]
fn dirty_tracker_marks_transform_dirty() {
    let mut tracker = DirtyTracker::new(100);
    assert!(!tracker.is_transform_dirty(0));
    tracker.mark_transform_dirty(0);
    assert!(tracker.is_transform_dirty(0));
}

#[test]
fn dirty_tracker_clear_resets_all() {
    let mut tracker = DirtyTracker::new(100);
    tracker.mark_transform_dirty(0);
    tracker.mark_transform_dirty(50);
    tracker.mark_bounds_dirty(25);
    tracker.clear();
    assert!(!tracker.is_transform_dirty(0));
    assert!(!tracker.is_transform_dirty(50));
    assert!(!tracker.is_bounds_dirty(25));
}

#[test]
fn dirty_tracker_dirty_ratio() {
    let mut tracker = DirtyTracker::new(100);
    for i in 0..30 {
        tracker.mark_transform_dirty(i);
    }
    assert!((tracker.transform_dirty_ratio(100) - 0.3).abs() < 0.01);
}
```

### Step 2: Run tests to verify they fail

Run: `cargo test -p hyperion-core render_state`
Expected: FAIL — `DirtyTracker` doesn't exist.

### Step 3: Implement

Add to `render_state.rs`:

```rust
/// Compact bitset for dirty tracking. Each bit represents one entity.
pub struct BitSet {
    bits: Vec<u64>,
    count: usize,
}

impl BitSet {
    pub fn new(capacity: usize) -> Self {
        Self { bits: vec![0; (capacity + 63) / 64], count: 0 }
    }

    pub fn set(&mut self, index: usize) {
        let word = index / 64;
        let bit = index % 64;
        if word < self.bits.len() {
            let mask = 1u64 << bit;
            if self.bits[word] & mask == 0 {
                self.bits[word] |= mask;
                self.count += 1;
            }
        }
    }

    pub fn get(&self, index: usize) -> bool {
        let word = index / 64;
        let bit = index % 64;
        word < self.bits.len() && (self.bits[word] & (1u64 << bit)) != 0
    }

    pub fn clear(&mut self) {
        for w in &mut self.bits { *w = 0; }
        self.count = 0;
    }

    pub fn count(&self) -> usize { self.count }

    pub fn ensure_capacity(&mut self, capacity: usize) {
        let needed = (capacity + 63) / 64;
        if needed > self.bits.len() {
            self.bits.resize(needed, 0);
        }
    }
}

pub struct DirtyTracker {
    pub transform_dirty: BitSet,
    pub bounds_dirty: BitSet,
    pub meta_dirty: BitSet,
}

impl DirtyTracker {
    pub fn new(capacity: usize) -> Self {
        Self {
            transform_dirty: BitSet::new(capacity),
            bounds_dirty: BitSet::new(capacity),
            meta_dirty: BitSet::new(capacity),
        }
    }

    pub fn mark_transform_dirty(&mut self, idx: usize) { self.transform_dirty.set(idx); }
    pub fn mark_bounds_dirty(&mut self, idx: usize) { self.bounds_dirty.set(idx); }
    pub fn mark_meta_dirty(&mut self, idx: usize) { self.meta_dirty.set(idx); }

    pub fn is_transform_dirty(&self, idx: usize) -> bool { self.transform_dirty.get(idx) }
    pub fn is_bounds_dirty(&self, idx: usize) -> bool { self.bounds_dirty.get(idx) }

    pub fn transform_dirty_ratio(&self, total: usize) -> f32 {
        if total == 0 { 0.0 } else { self.transform_dirty.count() as f32 / total as f32 }
    }

    pub fn clear(&mut self) {
        self.transform_dirty.clear();
        self.bounds_dirty.clear();
        self.meta_dirty.clear();
    }
}
```

Add `dirty_tracker: DirtyTracker` to `RenderState` and update `collect_gpu()` to call `dirty_tracker.clear()` at the start. The `command_processor` should mark entities dirty when processing SetPosition/SetRotation/SetScale commands. Full integration with partial upload is deferred to Phase 5.

### Step 4: Run tests to verify they pass

Run: `cargo test -p hyperion-core render_state`
Expected: ALL PASS.

### Step 5: Commit

```bash
git add crates/hyperion-core/src/render_state.rs
git commit -m "feat(render-state): add BitSet-based DirtyTracker for partial upload

Phase 4.5 — per-buffer dirty tracking (transform, bounds, meta) using
compact BitSet (12.5 KB per 100k entities). Prepares for Phase 5
partial upload optimization (threshold: <30% dirty → partial upload).

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

## Post-Plan: Integration and Wiring

After all 15 tasks are complete, the following integration work remains:

1. **Wire `renderer.ts` → RenderGraph**: Replace the monolithic `createRenderer()` with `RenderGraph` instantiation that adds `CullPass` + `ForwardPass`. The existing `renderer.ts` becomes a thin factory function.

2. **Wire Supervisor into worker-bridge**: `createWorkerBridge()` and `createFullIsolationBridge()` should create a `WorkerSupervisor`, start the heartbeat check interval, and call `onTimeout` → `degradeMode()`.

3. **Wire Backpressure into RingBufferProducer**: When `writeCommand()` returns `false`, enqueue into `PrioritizedCommandQueue`. Drain the queue at the start of each `tick()`.

4. **Wire engine-worker heartbeat**: After each `engine_update()`, call `Atomics.add(heartbeat, 0, 1)`.

5. **Update `main.ts`**: Switch from direct `renderer.render()` to `renderGraph.render()`.

6. **WASM rebuild**: `cd ts && npm run build:wasm` after all Rust changes.

7. **Visual regression test**: `cd ts && npm run dev` → verify 100 entities render correctly in browser.

8. **Full validation**: `cargo test -p hyperion-core && cargo clippy -p hyperion-core && cd ts && npm test && npx tsc --noEmit`

---

## Validation Checklist

- [ ] SoA layout produces same visual rendering as current monolithic layout
- [ ] RenderGraph with 2 nodes (CullPass → ForwardPass) produces same output
- [ ] Supervisor detects heartbeat timeout and fires callback
- [ ] Backpressure retry queue preserves critical commands (Spawn/Despawn)
- [ ] Prefix sum CPU reference produces correct exclusive scan
- [ ] TextureManager lazy allocation starts at 0 and grows to 16 on first load
- [ ] Dirty tracking BitSet correctly marks/clears individual entity indices
- [ ] MeshHandle and RenderPrimitive spawn with defaults on SpawnEntity
- [ ] SAB header is 32 bytes; existing ring buffer tests pass with new offsets
- [ ] TypedArray fast path produces identical results to DataView path
- [ ] All Rust tests pass: `cargo test -p hyperion-core`
- [ ] All TypeScript tests pass: `cd ts && npm test`
- [ ] Type check passes: `cd ts && npx tsc --noEmit`
- [ ] Clippy clean: `cargo clippy -p hyperion-core`
